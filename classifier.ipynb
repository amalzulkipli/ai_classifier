{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"llama3\")\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Answer in less than 10 words.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, thank you for talking.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Hello there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm good, thanks for asking!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"Hello, how are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Classify the following item as either a 'fruit' or a 'vegetable':\n",
    "Item: {item}\n",
    "\n",
    "Classification:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"llama3\")\n",
    "chain = prompt | model\n",
    "\n",
    "# Read from CSV and classify\n",
    "with open('items.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        item = row['item']\n",
    "        response = chain.invoke({\"item\": item})\n",
    "        # Handle the response based on its type\n",
    "        if isinstance(response, str):\n",
    "            classification = response.strip()\n",
    "        else:\n",
    "            classification = response.content.strip()\n",
    "        print(f\"{item}: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of fruits and vegetables\n",
    "items = [\"apple\", \"carrot\", \"banana\", \"broccoli\", \"orange\", \"tomato\", \"grape\", \"cucumber\"]\n",
    "\n",
    "# Create a prompt template for classification\n",
    "template = \"\"\"\n",
    "Classify the following item as either a 'fruit' or a 'vegetable'. Pick 'fruit' or 'vegetable' only. One word :\n",
    "Item: {item}\n",
    "\n",
    "Classification:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize the Ollama model\n",
    "model = OllamaLLM(model=\"llama3\")\n",
    "\n",
    "# Create the classification chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Iterate through the list and classify each item\n",
    "for item in items:\n",
    "    response = chain.invoke({\"item\": item})\n",
    "\n",
    "    # Check if response is a string or an object with content attribute\n",
    "    if isinstance(response, str):\n",
    "        classification = response.strip()\n",
    "    else:\n",
    "        classification = response.content.strip()\n",
    "    print(f\"{item}: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a CSV file\n",
    "items = [\"apple\", \"carrot\", \"banana\", \"broccoli\", \"orange\", \"tomato\", \"grape\", \"cucumber\"]\n",
    "\n",
    "with open('items.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['item'])  # Header\n",
    "    for item in items:\n",
    "        writer.writerow([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Classify the following item as either a 'fruit' or a 'vegetable'. Pick 'fruit' or 'vegetable' only. One word :\n",
    "Item: {item}\n",
    "\n",
    "Classification:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"llama3\")\n",
    "chain = prompt | model\n",
    "\n",
    "# Read from CSV and classify\n",
    "with open('items.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        item = row['item']\n",
    "        response = chain.invoke({\"item\": item})\n",
    "        # Handle the response based on its type\n",
    "        if isinstance(response, str):\n",
    "            classification = response.strip()\n",
    "        else:\n",
    "            classification = response.content.strip()\n",
    "        print(f\"{item}: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
